{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = [\n",
    "    'code',\n",
    "    'energy_100g',\n",
    "    'fat_100g',\n",
    "    'carbohydrates_100g',\n",
    "    'sugars_100g',\n",
    "    'proteins_100g',\n",
    "    'salt_100g',\n",
    "    'sodium_100g',\n",
    "]\n",
    "\n",
    "df = spark.read.option(\"delimiter\", \"\\t\") \\\n",
    "    .csv(csv_path, header=True, inferSchema=True) \\\n",
    "    .select(*useful_cols) \\\n",
    "    .na.drop() \\\n",
    "    .cache()\n",
    "\n",
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b01d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns), df.count()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
